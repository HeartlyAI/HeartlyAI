{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{15: {'num': 38, 'mean_other_scp_likelihoods': 34.21052631578947}, 35: {'num': 37, 'mean_other_scp_likelihoods': 21.62162162162162}, 50: {'num': 505, 'mean_other_scp_likelihoods': 35.95049504950495}, 80: {'num': 1761, 'mean_other_scp_likelihoods': 10.724020442930152}, 100: {'num': 7172, 'mean_other_scp_likelihoods': 2.1730340211935304}}\n",
      "ecg_id\n",
      "1     {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}\n",
      "2                 {'NORM': 80.0, 'SBRAD': 0.0}\n",
      "3                   {'NORM': 100.0, 'SR': 0.0}\n",
      "4                   {'NORM': 100.0, 'SR': 0.0}\n",
      "5                   {'NORM': 100.0, 'SR': 0.0}\n",
      "6                   {'NORM': 100.0, 'SR': 0.0}\n",
      "7                   {'NORM': 100.0, 'SR': 0.0}\n",
      "8       {'IMI': 35.0, 'ABQRS': 0.0, 'SR': 0.0}\n",
      "9                   {'NORM': 100.0, 'SR': 0.0}\n",
      "10                  {'NORM': 100.0, 'SR': 0.0}\n",
      "Name: scp_codes, dtype: object\n",
      "ecg_id\n",
      "1     [NORM]\n",
      "2     [NORM]\n",
      "3     [NORM]\n",
      "4     [NORM]\n",
      "5     [NORM]\n",
      "6     [NORM]\n",
      "7     [NORM]\n",
      "8         []\n",
      "9     [NORM]\n",
      "10    [NORM]\n",
      "Name: normdiagnostic, dtype: object\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19601, 1000, 1), (19601, 1), (2198, 1000, 1), (2198, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import utils\n",
    "import numpy as np\n",
    "\n",
    "sampling_frequency=100\n",
    "datafolder='../data/ptbxl/'\n",
    "\n",
    "task='normabnorm'\n",
    "input_channels = 1 # number of leads\n",
    "experiment = 'custom_exp'\n",
    "modelname = f'fastai_xresnet1d101{\"_\"+str(input_channels)+\"lead\" if input_channels!=12 else \"\"}'\n",
    "\n",
    "outputfolder='../output/'\n",
    "\n",
    "# Load PTB-XL data\n",
    "data, raw_labels = utils.load_dataset(datafolder, sampling_frequency)\n",
    "# Preprocess label data\n",
    "scp = raw_labels.scp_codes\n",
    "counts = {}\n",
    "\n",
    "for threshold in range(5, 105, 5):\n",
    "    indices = [i for i, d in enumerate(scp) if 'NORM' in d and d['NORM'] == threshold]\n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "    mean_other_scp_likelihoods = sum([sum([v for k,v in d.items() if k!=\"NORM\"]) for i, d in enumerate(scp.iloc[indices])])/len(indices)\n",
    "\n",
    "    meta = {\"num\": len(indices), \"mean_other_scp_likelihoods\": mean_other_scp_likelihoods}\n",
    "    counts[threshold] = meta\n",
    "\n",
    "print({k: v for k, v in counts.items() if v[\"num\"] > 0})\n",
    "\n",
    "print(raw_labels[\"scp_codes\"].head(10))\n",
    "labels = utils.compute_label_aggregations(raw_labels, datafolder,task)\n",
    "\n",
    "if task == \"all\":\n",
    "    print(labels[\"all_scp\"].head(2))\n",
    "    \n",
    "elif task==\"normabnorm\":\n",
    "    print(labels[\"normdiagnostic\"].head(10))\n",
    "\n",
    "\n",
    "# Select relevant data and convert to one-hot\n",
    "data, labels, Y, mlb = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
    "for i in range(10):\n",
    "    print(Y[i])\n",
    "\n",
    "\n",
    "# Max input_channels is 12\n",
    "# Extract the first input_channels leads from each sample in data\n",
    "data = np.array([d[:,:input_channels] for d in data])\n",
    "\n",
    "# 1-9 for training \n",
    "X_train = data[labels.strat_fold < 10]\n",
    "y_train = Y[labels.strat_fold < 10]\n",
    "# 10 for validation\n",
    "X_val = data[labels.strat_fold == 10]\n",
    "y_val = Y[labels.strat_fold == 10]\n",
    "\n",
    "num_classes = 1 \n",
    "\n",
    "input_shape = [1000, input_channels] # <=== shape of samples, [None, 12] in case of different lengths\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model\n",
    "\n",
    "For loading a pretrained model:\n",
    "   1. specify `modelname` which can be seen in `code/configs/` (e.g. `modelname='fastai_xresnet1d101'`)\n",
    "   2. provide `experiment` to build the path `pretrainedfolder` (here: `custom_exp` refers to the experiment that only extracts wether the sample is normal or abnormal from the SCP-statements)\n",
    "   \n",
    "This returns the pretrained model where the classification is replaced by a random initialized head with the same number of outputs as the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/custom_exp/models/fastai_xresnet1d101_1lead/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.fastai_model import fastai_model\n",
    "\n",
    "pretrainedfolder = '../output/'+experiment+'/models/'+modelname+'/'\n",
    "mpath = '../output/'+experiment+'/models/'+modelname+'/' # <=== path where the finetuned model will be stored\n",
    "n_classes_pretrained = num_classes # <=== because we load the model from exp0, this should be fixed because this depends the experiment\n",
    "\n",
    "model = fastai_model(\n",
    "    modelname, \n",
    "    num_classes, \n",
    "    sampling_frequency, \n",
    "    mpath, \n",
    "    input_shape=input_shape, \n",
    "    input_channels=input_channels,\n",
    "    pretrainedfolder=pretrainedfolder,\n",
    "    n_classes_pretrained=n_classes_pretrained, \n",
    "    pretrained=True,\n",
    "    epochs_finetuning=2,\n",
    ")\n",
    "\n",
    "model.input_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data with pretrained Standardizer\n",
    "\n",
    "Since we standardize inputs to zero mean and unit variance, your custom data needs to be standardized with the respective mean and variance. This is also provided in the respective experiment folder `output/expX/data/standard_scaler.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "standard_scaler = pickle.load(open('../output/'+experiment+'/data/standard_scaler.pkl', \"rb\"))\n",
    "\n",
    "X_train = utils.apply_standardizer(X_train, standard_scaler)\n",
    "X_val = utils.apply_standardizer(X_val, standard_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19601, 1000, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2198, 1000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_val[:]\n",
    "y_test = y_val[:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In channels: 1, shape: [1000, 1]\n",
      "model: fastai_xresnet1d101_1lead\n",
      "HEIHEI\n",
      "1\n",
      "fastai_xresnet1d101_1lead\n",
      "../output/custom_exp/models/fastai_xresnet1d101_1lead/models/fastai_xresnet1d101_1lead.pth\n",
      "Model exported to ../output/custom_exp/models/fastai_xresnet1d101_1lead/models/model.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_file_path = mpath + 'models/model.onnx'\n",
    "model.to_onnx(X_test, onnx_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of chunks: (15386, 250, 1)\n",
      "SHape before transpose: (15386, 250, 1)\n",
      "SHape after transpose: (15386, 1, 250)\n",
      "Shape of predictions before: (15386, 1)\n",
      "Shape of predictions after sigmoid: (15386, 1)\n",
      "aggregating predictions...\n"
     ]
    }
   ],
   "source": [
    "# this function requires ONLY numpy and onnxruntime\n",
    "from utils.onnx import onnx_predict\n",
    "y_test_pred_onnx = onnx_predict(X_test, onnx_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find where y_test_pred_onnx is nan\n",
    "nan_indices = np.argwhere(np.isnan(y_test_pred_onnx))\n",
    "nan_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set nan to 0\n",
    "y_test_pred_onnx[nan_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_thresholds = utils.find_optimal_cutoff_thresholds(y_test, y_test_pred_onnx)\n",
    "# optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, idxs=[0], \tactual=[1],  onnx= [0.889828]\n",
      "i=1, idxs=[0], \tactual=[1],  onnx= [0.893311]\n",
      "i=2, idxs=[0], \tactual=[1],  onnx= [0.461641]\n",
      "i=3, idxs=[0], \tactual=[1],  onnx= [0.954705]\n",
      "i=4, idxs=[0], \tactual=[1],  onnx= [0.892052]\n",
      "i=5, idxs=[0], \tactual=[0],  onnx= [0.847784]\n",
      "i=6, idxs=[0], \tactual=[0],  onnx= [0.944056]\n",
      "i=7, idxs=[0], \tactual=[1],  onnx= [0.914132]\n",
      "i=8, idxs=[0], \tactual=[1],  onnx= [0.865871]\n",
      "i=9, idxs=[0], \tactual=[1],  onnx= [0.89439]\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = 0.75\n",
    "\n",
    "for i in range(10):\n",
    "    idxs = [0]#np.where(y_test[i] > optimal_threshold)[0]\n",
    "    nan_indices = np.argwhere(np.isnan(y_test_pred_onnx[i]))\n",
    "    print(f\"i={i}, idxs={idxs}, \\tactual={y_test[i][idxs]},  onnx= {y_test_pred_onnx[i][idxs]}\")#\\ttest_pred = {y_test_pred[i][idxs]}\")\n",
    "\n",
    "optimal_thresholds = [optimal_threshold] * num_classes\n",
    "y_test_pred_onnx_binary = utils.apply_thresholds(y_test_pred_onnx, optimal_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NORM',),\n",
       " ('NORM',),\n",
       " (),\n",
       " ('NORM',),\n",
       " ('NORM',),\n",
       " ('NORM',),\n",
       " ('NORM',),\n",
       " ('NORM',),\n",
       " ('NORM',),\n",
       " ('NORM',)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_classes = mlb.inverse_transform(y_test)\n",
    "\n",
    "# y_test_pred_binary = utils.apply_thresholds(y_test_pred, optimal_thresholds)\n",
    "# predicted_classes = mlb.inverse_transform(y_test_pred_binary)\n",
    "\n",
    "predicted_classes_onnx = mlb.inverse_transform(y_test_pred_onnx_binary)\n",
    "predicted_classes_onnx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of NORM in actual_classes: 0.4381255686988171\n",
      "% of NORM in onnx predicted classes: 0.41264786169244766\n"
     ]
    }
   ],
   "source": [
    "onnx_is_norm = ['NORM' in str(a) for a in predicted_classes_onnx]\n",
    "# pred_is_norm = ['NORM' in str(a) for a in predicted_classes]\n",
    "actual_is_norm = ['NORM' in str(a) for a in actual_classes]\n",
    "print(f\"% of NORM in actual_classes: {sum(actual_is_norm)/len(actual_is_norm)}\")\n",
    "print(f\"% of NORM in onnx predicted classes: {sum(onnx_is_norm)/len(onnx_is_norm)}\")\n",
    "# print(f\"% of NORM in predicted classes: {sum(pred_is_norm)/len(pred_is_norm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952684258416742"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_norm_accuracy(predicted_is_norm, actual_is_norm):\n",
    "    correct_predictions = [1 if a==b else 0 for a, b in zip(predicted_is_norm, actual_is_norm)]\n",
    "    accuracy = sum(correct_predictions) / len(correct_predictions)\n",
    "    return accuracy\n",
    "onnx_accuracy_norm = calculate_norm_accuracy(onnx_is_norm, actual_is_norm)\n",
    "# pred_accuracy_norm = calculate_norm_accuracy(pred_is_norm, actual_is_norm)\n",
    "onnx_accuracy_norm#, pred_accuracy_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_norm_specificity_and_sensitivity(predicted_is_norm, actual_is_norm):\n",
    "    true_positives = sum([1 if a and b else 0 for a, b in zip(predicted_is_norm, actual_is_norm)])\n",
    "    true_negatives = sum([1 if not a and not b else 0 for a, b in zip(predicted_is_norm, actual_is_norm)])\n",
    "    false_positives = sum([1 if a and not b else 0 for a, b in zip(predicted_is_norm, actual_is_norm)])\n",
    "    false_negatives = sum([1 if not a and b else 0 for a, b in zip(predicted_is_norm, actual_is_norm)])\n",
    "    sensitivity = true_positives / (true_positives + false_negatives)\n",
    "    specificity = true_negatives / (true_negatives + false_positives)\n",
    "    return sensitivity, specificity\n",
    "\n",
    "def calculate_f1_score(predicted_is_norm, actual_is_norm):\n",
    "    sensitivity, specificity = calculate_norm_specificity_and_sensitivity(predicted_is_norm, actual_is_norm)\n",
    "    f1_score = 2 * (sensitivity * specificity) / (sensitivity + specificity)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7952684258416742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Specificity: 0.7372793354101765, Sensitivity: 0.8404858299595142, F1-Score: 0.7855070548335042'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity, sensitivity = calculate_norm_specificity_and_sensitivity(onnx_is_norm, actual_is_norm)\n",
    "f1_score = calculate_f1_score(onnx_is_norm, actual_is_norm)\n",
    "\n",
    "print(f\"Accuracy: {onnx_accuracy_norm}\")\n",
    "f\"Specificity: {specificity}, Sensitivity: {sensitivity}, F1-Score: {f1_score}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
